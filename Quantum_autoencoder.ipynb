{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yEkkz043jjE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac408190-52b9-4e87-92ed-a1e22562b51f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 KB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 KB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q pennylane"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4fndLuV3zef"
      },
      "source": [
        "# Variational Quantum Autoencoder\n",
        "\n",
        "A variational quantum autoencoder (VQAE) is a type of quantum machine learning algorithm that combines the power of quantum computing and neural networks to perform data compression and reconstruction. It is a natural extension of classical autoencoders, which are widely used in deep learning to compress and decompress high-dimensional data. In contrast to classical autoencoders, VQAEs use quantum circuits to encode and decode data, and can therefore take advantage of the unique properties of quantum mechanics, such as superposition and entanglement, to achieve better data compression and higher accuracy in reconstruction.\n",
        "\n",
        "The VQAE architecture consists of three main components: an encoder quantum circuit, a decoder quantum circuit, and a classical neural network that acts as an optimizer. The encoder circuit maps the input data into a lower-dimensional quantum state, which is then fed into the decoder circuit to reconstruct the original data. The optimization process is used to minimize the difference between the input and output data by adjusting the parameters of the quantum circuits and the neural network.\n",
        "\n",
        "One of the key advantages of VQAEs is their ability to learn from a limited amount of training data, which is particularly useful in situations where data is scarce or expensive to obtain. VQAEs can also be used for unsupervised learning, which means they can identify patterns and features in data without the need for explicit labels.\n",
        "\n",
        "VQAEs are still in the early stages of development, and there are many challenges that need to be overcome before they can be applied to real-world problems. However, they hold great promise for the future of quantum machine learning, and could potentially lead to breakthroughs in areas such as drug discovery, materials science, and optimization.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eMwdG_T7o9l"
      },
      "source": [
        "### Download dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcR4XaTv7uBj"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pennylane as qml\n",
        "import pennylane.numpy as np\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Q-ZNFrdYfcy"
      },
      "outputs": [],
      "source": [
        "X, y = datasets.load_wine(return_X_y=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_cca-q9053d"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_scaled = scaler.fit_transform(X)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cN992oQ1z7p"
      },
      "outputs": [],
      "source": [
        "# # wrong encoding\n",
        "# n_qubits = 4\n",
        "# dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "# @qml.qnode(dev)\n",
        "# def circuit(feature_vector):\n",
        "#   U = np.eye(2 ** n_qubits, dtype=complex)\n",
        "#   for i in range(len(feature_vector)):\n",
        "#     #print(feature_vector[i])\n",
        "#     U[i, i] = np.exp(1j * feature_vector[i] * np.pi)\n",
        "#   #print(U)\n",
        "#   qml.QubitUnitary(U, wires=range(n_qubits))\n",
        "#   return qml.state()\n",
        "\n",
        "# print(circuit(X_scaled[0]))\n",
        "# print(circuit(X_scaled[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zmoMfC-7TyT"
      },
      "outputs": [],
      "source": [
        "# correct encoding\n",
        "n_qubits = 4\n",
        "dev = qml.device('default.qubit', wires=n_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(feature_vector):\n",
        "  qml.AmplitudeEmbedding(features=np.exp(1j * np.pi * feature_vector), wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "  return qml.state()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1bthi9MmQ02"
      },
      "outputs": [],
      "source": [
        "def phase_embedding_layer(x):\n",
        "  qml.AmplitudeEmbedding(features=np.exp(1j * np.pi * x), wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "  #qml.AmplitudeEmbedding(features=x, wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "\n",
        "def encoding_layer(params):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(params[i], wires=i)\n",
        "    for i in range(n_qubits-1):\n",
        "      qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
        "\n",
        "def decoding_layer(params):\n",
        "    for i in range(n_qubits-1):\n",
        "      k = n_qubits - i - 1\n",
        "      qml.CNOT(wires=[k, (k+1)%n_qubits])\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(-params[i], wires=i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO8v2aunGUIi"
      },
      "outputs": [],
      "source": [
        "n_qubits = 4\n",
        "n_layers = 10\n",
        "measure_qubits = [0,1]\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqry2CIFWWUc"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev)\n",
        "def encoding_circuit(params, x, mqubits=None):\n",
        "    phase_embedding_layer(x)\n",
        "    for i in range(n_layers):\n",
        "        encoding_layer(params[i])\n",
        "    if mqubits is None:\n",
        "        for i in range(len(measure_qubits)):\n",
        "            qml.measure(i)\n",
        "        return qml.state()\n",
        "    \n",
        "    return [\n",
        "        qml.expval(qml.PauliZ(wires=measure_qubits[i]))\n",
        "        for i in range(len(measure_qubits))\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szpCoOFMfmha",
        "outputId": "b4542e67-3f67-4858-9fbe-6045ca2fae64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 20: Cost = 0.6403648396144628\n",
            "Step 40: Cost = 0.2665549105628565\n",
            "Step 60: Cost = 0.09694793857885897\n",
            "Step 80: Cost = 0.04408708911920467\n",
            "Step 100: Cost = 0.026128196859139363\n",
            "Step 120: Cost = 0.013601760721008826\n",
            "Step 140: Cost = 0.006574403744542767\n",
            "Step 160: Cost = 0.0032333779669293516\n",
            "Step 180: Cost = 0.0015906761358953636\n",
            "Step 200: Cost = 0.0007104493533709455\n",
            "Step 220: Cost = 0.00026933528667760775\n",
            "Step 240: Cost = 8.316991106327443e-05\n",
            "Step 260: Cost = 2.0006275856632172e-05\n",
            "Step 280: Cost = 3.5013492308832994e-06\n",
            "Step 300: Cost = 3.961888113135359e-07\n",
            "Step 320: Cost = 2.4924684205451797e-08\n",
            "Step 340: Cost = 2.037975233015743e-09\n",
            "Step 360: Cost = 4.743956338870703e-10\n",
            "Step 380: Cost = 4.751521398560499e-11\n",
            "Step 400: Cost = 5.6632476486129235e-12\n",
            "Step 420: Cost = 8.546496843564455e-13\n",
            "Step 440: Cost = 5.762057497804562e-14\n",
            "Step 460: Cost = 1.7430501486614958e-14\n",
            "Step 480: Cost = 0.0\n",
            "Step 500: Cost = 4.440892098500626e-16\n",
            "Step 520: Cost = 1.9095836023552692e-14\n",
            "Step 540: Cost = 1.1102230246251565e-15\n",
            "Step 560: Cost = 1.2212453270876722e-15\n",
            "Step 580: Cost = 2.375877272697835e-14\n",
            "Step 600: Cost = 8.104628079763643e-15\n",
            "Step 620: Cost = 2.4424906541753444e-15\n",
            "Step 640: Cost = 1.5543122344752192e-15\n",
            "Step 660: Cost = 8.419356323230431e-10\n",
            "Step 680: Cost = 3.403786952294041e-08\n",
            "Step 700: Cost = 4.3038431707387304e-08\n",
            "Step 720: Cost = 8.916994920227239e-09\n",
            "Step 740: Cost = 5.070543318552723e-09\n",
            "Step 760: Cost = 3.861020858808573e-06\n",
            "Step 780: Cost = 9.662657178832745e-07\n",
            "Step 800: Cost = 3.6457322715177654e-06\n",
            "Step 820: Cost = 6.084443429976716e-06\n",
            "Step 840: Cost = 2.1156082330442416e-08\n",
            "Step 860: Cost = 5.6576262785767995e-08\n",
            "Step 880: Cost = 1.836546217615087e-05\n",
            "Step 900: Cost = 1.4702482786788096e-08\n",
            "Step 920: Cost = 7.222434377229803e-07\n",
            "Step 940: Cost = 2.053068281404613e-05\n",
            "Step 960: Cost = 5.1447810447413644e-06\n",
            "Step 980: Cost = 2.583261882183052e-06\n",
            "Step 1000: Cost = 4.601891102073985e-06\n"
          ]
        }
      ],
      "source": [
        "opt = qml.AdamOptimizer()\n",
        "\n",
        "def loss_fn(params, X, measure_qubits):\n",
        "    val = encoding_circuit(params, X, mqubits=measure_qubits)\n",
        "    return np.sum(np.abs(1 - val))\n",
        "\n",
        "params = np.array([\n",
        "    [np.random.uniform(0, 2 * np.pi) for _ in range(n_qubits)] for _ in range(n_layers)], requires_grad=True)\n",
        "\n",
        "costs=[]\n",
        "for i in range(1000):\n",
        "    params, cost_val = opt.step_and_cost(lambda v: loss_fn(v, X_scaled, measure_qubits), params)\n",
        "    costs.append(cost_val)\n",
        "    if (i + 1) % 20 == 0:\n",
        "        print('Step {}: Cost = {}'.format(i + 1, cost_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "3hnqHMet3IJz",
        "outputId": "1bfaf50c-1d0f-4824-886c-a319c8b3c21c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot cost history\n",
        "plt.plot(costs)\n",
        "plt.xlabel(\"Optimization step\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.ylim(0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWZ15dWt4Gg_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rTO_UeM44Ha6"
      },
      "source": [
        "## 2-qubit case (revisited)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6WgH6Zw4ObQ"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "import pennylane.numpy as np\n",
        "from pennylane.templates.embeddings import AmplitudeEmbedding\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def phase_embedding_layer(x):\n",
        "  qml.AmplitudeEmbedding(features=np.exp(1j * np.pi * x), wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "\n",
        "def encoding_layer(params):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(params[i], wires=i)\n",
        "    for i in range(n_qubits):\n",
        "      qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
        "\n",
        "def decoding_layer(params):\n",
        "    for i in range(n_qubits):\n",
        "      k = n_qubits - i - 1\n",
        "      qml.CNOT(wires=[k, (k+1)%n_qubits])\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(-params[i], wires=i)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGsXog4u4j_L"
      },
      "outputs": [],
      "source": [
        "n_qubits = 2\n",
        "n_layers = 4\n",
        "measure_qubits = [0]\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fj7rvAVR4qBY"
      },
      "outputs": [],
      "source": [
        "@qml.qnode(dev)\n",
        "def encoding_circuit(params, x, measure_qubits=None):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  if measure_qubits is None:\n",
        "    return qml.state()\n",
        "  if (len(measure_qubits) == 2):\n",
        "    return qml.expval(qml.PauliZ(wires=measure_qubits[0])), qml.expval(qml.PauliZ(wires=measure_qubits[1]))  \n",
        "  return qml.expval(qml.PauliZ(wires=measure_qubits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO9xa2cf4r7q"
      },
      "outputs": [],
      "source": [
        "xval = np.random.uniform(\n",
        "    0,\n",
        "    np.pi,\n",
        "    2**n_qubits,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3JczTsv5DNQ",
        "outputId": "f232199d-ad4f-4d8d-91b9-64edb5226243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10: Cost = 0.6543894227818412\n",
            "Step 20: Cost = 0.5076924248980641\n",
            "Step 30: Cost = 0.36994695188319215\n",
            "Step 40: Cost = 0.23911393555013682\n",
            "Step 50: Cost = 0.13143203186806363\n",
            "Step 60: Cost = 0.05916281819446545\n",
            "Step 70: Cost = 0.02009835634174173\n",
            "Step 80: Cost = 0.004330699212578559\n",
            "Step 90: Cost = 0.00045411048022003797\n",
            "Step 100: Cost = 0.00020859785385651808\n",
            "Step 110: Cost = 0.00023017895684174228\n",
            "Step 120: Cost = 0.00010566222186758623\n",
            "Step 130: Cost = 1.9499601922823295e-05\n",
            "Step 140: Cost = 1.2203590554760169e-06\n",
            "Step 150: Cost = 2.8693805419477414e-06\n",
            "Step 160: Cost = 1.9063234716343302e-06\n",
            "Step 170: Cost = 3.0606388001785945e-07\n",
            "Step 180: Cost = 7.2981398702154365e-09\n",
            "Step 190: Cost = 6.228745841330152e-08\n",
            "Step 200: Cost = 2.7111255018752445e-08\n",
            "Step 210: Cost = 1.1289157386684678e-09\n",
            "Step 220: Cost = 1.956557027504857e-09\n",
            "Step 230: Cost = 1.1975603841918314e-09\n",
            "Step 240: Cost = 7.2065797773746e-11\n",
            "Step 250: Cost = 1.182025588519764e-10\n",
            "Step 260: Cost = 4.127587160951407e-11\n",
            "Step 270: Cost = 2.758460126983664e-12\n",
            "Step 280: Cost = 7.834621840174805e-12\n",
            "Step 290: Cost = 5.044853423896711e-13\n",
            "Step 300: Cost = 6.050715484207103e-13\n",
            "Step 310: Cost = 2.474687121889474e-13\n",
            "Step 320: Cost = 2.5091040356528538e-14\n",
            "Step 330: Cost = 4.030109579389318e-14\n",
            "Step 340: Cost = 2.9976021664879227e-15\n",
            "Step 350: Cost = 4.440892098500626e-15\n",
            "Step 360: Cost = 3.3306690738754696e-16\n",
            "Step 370: Cost = 6.661338147750939e-16\n",
            "Step 380: Cost = 0.0\n",
            "Step 390: Cost = 6.661338147750939e-16\n",
            "Step 400: Cost = 5.551115123125783e-16\n",
            "Step 410: Cost = 2.220446049250313e-16\n",
            "Step 420: Cost = 3.3306690738754696e-16\n",
            "Step 430: Cost = 1.1102230246251565e-16\n",
            "Step 440: Cost = 0.0\n",
            "Step 450: Cost = 0.0\n",
            "Step 460: Cost = 4.440892098500626e-16\n",
            "Step 470: Cost = 2.220446049250313e-16\n",
            "Step 480: Cost = 0.0\n",
            "Step 490: Cost = 4.440892098500626e-16\n",
            "Step 500: Cost = 1.1102230246251565e-16\n",
            "Step 510: Cost = 2.220446049250313e-16\n",
            "Step 520: Cost = 4.440892098500626e-16\n",
            "Step 530: Cost = 0.0\n",
            "Step 540: Cost = 1.1102230246251565e-16\n",
            "Step 550: Cost = 0.0\n",
            "Step 560: Cost = 1.1102230246251565e-16\n",
            "Step 570: Cost = 0.0\n",
            "Step 580: Cost = 3.3306690738754696e-16\n",
            "Step 590: Cost = 0.0\n",
            "Step 600: Cost = 2.220446049250313e-16\n",
            "Step 610: Cost = 5.551115123125783e-16\n",
            "Step 620: Cost = 0.0\n",
            "Step 630: Cost = 3.3306690738754696e-16\n",
            "Step 640: Cost = 0.0\n",
            "Step 650: Cost = 5.551115123125783e-16\n",
            "Step 660: Cost = 4.440892098500626e-16\n",
            "Step 670: Cost = 0.0\n",
            "Step 680: Cost = 2.220446049250313e-16\n",
            "Step 690: Cost = 4.440892098500626e-16\n",
            "Step 700: Cost = 0.0\n",
            "Step 710: Cost = 0.0\n",
            "Step 720: Cost = 1.1102230246251565e-16\n",
            "Step 730: Cost = 1.4432899320127035e-15\n",
            "Step 740: Cost = 4.440892098500626e-16\n",
            "Step 750: Cost = 0.0\n",
            "Step 760: Cost = 9.992007221626409e-16\n",
            "Step 770: Cost = 2.220446049250313e-16\n",
            "Step 780: Cost = 0.0\n",
            "Step 790: Cost = 2.220446049250313e-16\n",
            "Step 800: Cost = 6.661338147750939e-16\n",
            "Step 810: Cost = 7.771561172376096e-16\n",
            "Step 820: Cost = 6.661338147750939e-16\n",
            "Step 830: Cost = 0.0\n",
            "Step 840: Cost = 1.887379141862766e-15\n",
            "Step 850: Cost = 4.440892098500626e-16\n",
            "Step 860: Cost = 3.3306690738754696e-16\n",
            "Step 870: Cost = 4.551914400963142e-15\n",
            "Step 880: Cost = 8.881784197001252e-16\n",
            "Step 890: Cost = 2.220446049250313e-16\n",
            "Step 900: Cost = 1.1102230246251565e-16\n",
            "Step 910: Cost = 4.107825191113079e-15\n",
            "Step 920: Cost = 1.1102230246251565e-15\n",
            "Step 930: Cost = 6.661338147750939e-16\n",
            "Step 940: Cost = 8.881784197001252e-16\n",
            "Step 950: Cost = 7.216449660063518e-15\n",
            "Step 960: Cost = 2.3314683517128287e-15\n",
            "Step 970: Cost = 1.4432899320127035e-15\n",
            "Step 980: Cost = 1.3322676295501878e-15\n",
            "Step 990: Cost = 9.992007221626409e-16\n",
            "Step 1000: Cost = 1.2212453270876722e-15\n"
          ]
        }
      ],
      "source": [
        "opt = qml.AdamOptimizer()\n",
        "\n",
        "def loss_fn(params, X, measure_qubits):\n",
        "  val = encoding_circuit(params, X, measure_qubits=measure_qubits)\n",
        "  return np.mean(np.abs(1-val))\n",
        "\n",
        "\n",
        "params = np.array([\n",
        "    [np.random.uniform(0, 2 * np.pi) for _ in range(n_qubits)] for _ in range(n_layers)\n",
        "], requires_grad=True)\n",
        "tot_iter = 1000\n",
        "costs=[]\n",
        "for i in range(tot_iter):\n",
        "    params, cost_val = opt.step_and_cost(lambda v: loss_fn(v, xval, measure_qubits), params)\n",
        "    costs.append(cost_val)\n",
        "    if (i + 1) % (tot_iter/100) == 0:\n",
        "        print('Step {}: Cost = {}'.format(i + 1, cost_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot cost history\n",
        "plt.plot(costs)\n",
        "plt.xlabel(\"Optimization step\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.ylim(0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "kpE0gyFfh3Xv",
        "outputId": "f4c8c576-380f-4187-973a-c2169e25a267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "opt_params = params"
      ],
      "metadata": {
        "id": "oITuYb_c5o0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ECJtwOcyFgR9",
        "outputId": "49e77075-a4af-4622-fd01-59ac337fdcb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.559182  , 4.63126161],\n",
              "        [3.7084734 , 0.92342611],\n",
              "        [6.03709028, 6.14763942],\n",
              "        [4.79766455, 2.86500368]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 4\n",
        "m_qubits = ['m0']\n",
        "c_qubits = ['c0']\n",
        "a_qubits = ['a0']\n",
        "dev = qml.device(\"default.qubit\", wires=m_qubits+c_qubits+a_qubits)\n",
        "xval = np.random.uniform(\n",
        "    0,\n",
        "    np.pi,\n",
        "    2**n_qubits,\n",
        ")\n",
        "all_qubits = m_qubits+c_qubits\n",
        "print(all_qubits)"
      ],
      "metadata": {
        "id": "l7LMXcaKHIGh",
        "outputId": "2a189ad3-f396-42db-f7a4-850355d5ed81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['m0', 'c0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 4\n",
        "m_qubits = ['m0']\n",
        "c_qubits = ['c0']\n",
        "a_qubits = ['a0']\n",
        "dev = qml.device(\"default.qubit\", wires=m_qubits+c_qubits+a_qubits)\n",
        "xval = np.random.uniform(\n",
        "    0,\n",
        "    np.pi,\n",
        "    2**n_qubits,\n",
        ")\n",
        "\n",
        "def phase_embedding_layer(x):\n",
        "  qml.AmplitudeEmbedding(features=np.exp(1j * np.pi * x), wires=m_qubits+c_qubits, pad_with=0.0, normalize=True)\n",
        "  #qml.AmplitudeEmbedding(features=x, wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "\n",
        "def encoding_layer(params):\n",
        "  all_qubits = m_qubits+c_qubits\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    qml.RY(params[i], wires=q)\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    if i + 1 < len(all_qubits):\n",
        "      qml.CNOT(wires=[q, all_qubits[i+1]])\n",
        "\n",
        "def decoding_layer(params):\n",
        "  all_qubits = a_qubits+c_qubits\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    k = len(all_qubits) - i - 1\n",
        "    if k+1 < len(all_qubits):\n",
        "      qml.CNOT(wires=[all_qubits[k], all_qubits[k+1]])\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    qml.RY(-params[i], wires=q)"
      ],
      "metadata": {
        "id": "BV2lM1yR5sFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = qml.AdamOptimizer()\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def encode_loop(params, x):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  return qml.expval(qml.PauliZ(wires=m_qubits))\n",
        "\n",
        "\n",
        "def loss_fn(params, X):\n",
        "  e_val = encode_loop(params, X)\n",
        "  return np.mean(np.abs(1-e_val))\n",
        "\n",
        "\n",
        "params = np.array([\n",
        "    [np.random.uniform(0, 2 * np.pi) for _ in range(n_qubits)] for _ in range(n_layers)\n",
        "], requires_grad=True)\n",
        "opt_params = np.zeros_like(params)\n",
        "tot_iter = 1000\n",
        "costs=[]\n",
        "for i in range(tot_iter):\n",
        "  params, cost_val = opt.step_and_cost(lambda v: loss_fn(v, xval), params)\n",
        "  costs.append(cost_val)\n",
        "  if (i + 1) % (tot_iter/100) == 0:\n",
        "    print('Step {}: Cost = {}'.format(i + 1, cost_val))\n",
        "  opt_params = params\n",
        "    "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcqfDZSkJqSl",
        "outputId": "675643de-3729-466d-ffac-57d39f9f342c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10: Cost = 0.3484939799111004\n",
            "Step 20: Cost = 0.16404906384492834\n",
            "Step 30: Cost = 0.06312606471793836\n",
            "Step 40: Cost = 0.01488519104803221\n",
            "Step 50: Cost = 0.00411525550534575\n",
            "Step 60: Cost = 0.002330772382092783\n",
            "Step 70: Cost = 0.0014352682586141752\n",
            "Step 80: Cost = 0.00037097721340950685\n",
            "Step 90: Cost = 3.3337248138143316e-05\n",
            "Step 100: Cost = 2.0237304671821832e-05\n",
            "Step 110: Cost = 2.0888886968051246e-05\n",
            "Step 120: Cost = 6.558285374103079e-06\n",
            "Step 130: Cost = 2.725759027155661e-06\n",
            "Step 140: Cost = 1.8520907378860585e-06\n",
            "Step 150: Cost = 7.271250287432807e-07\n",
            "Step 160: Cost = 4.285697777772768e-07\n",
            "Step 170: Cost = 2.7842568750546803e-07\n",
            "Step 180: Cost = 1.373107583191313e-07\n",
            "Step 190: Cost = 7.500121179671027e-08\n",
            "Step 200: Cost = 3.7575233702291655e-08\n",
            "Step 210: Cost = 1.7841932820061857e-08\n",
            "Step 220: Cost = 7.887282826857245e-09\n",
            "Step 230: Cost = 3.0709504938997156e-09\n",
            "Step 240: Cost = 1.1173473257741762e-09\n",
            "Step 250: Cost = 3.293435524298616e-10\n",
            "Step 260: Cost = 7.960110348648186e-11\n",
            "Step 270: Cost = 1.180944231293779e-11\n",
            "Step 280: Cost = 8.907319326567631e-13\n",
            "Step 290: Cost = 3.540501225529624e-13\n",
            "Step 300: Cost = 7.657208200839705e-13\n",
            "Step 310: Cost = 5.211386877590485e-13\n",
            "Step 320: Cost = 2.1094237467877974e-13\n",
            "Step 330: Cost = 5.440092820663267e-14\n",
            "Step 340: Cost = 4.440892098500626e-15\n",
            "Step 350: Cost = 3.3306690738754696e-16\n",
            "Step 360: Cost = 1.1102230246251565e-15\n",
            "Step 370: Cost = 9.992007221626409e-16\n",
            "Step 380: Cost = 0.0\n",
            "Step 390: Cost = 2.220446049250313e-16\n",
            "Step 400: Cost = 0.0\n",
            "Step 410: Cost = 0.0\n",
            "Step 420: Cost = 2.220446049250313e-16\n",
            "Step 430: Cost = 4.440892098500626e-16\n",
            "Step 440: Cost = 6.661338147750939e-16\n",
            "Step 450: Cost = 4.440892098500626e-16\n",
            "Step 460: Cost = 0.0\n",
            "Step 470: Cost = 1.1102230246251565e-16\n",
            "Step 480: Cost = 2.220446049250313e-16\n",
            "Step 490: Cost = 0.0\n",
            "Step 500: Cost = 1.1102230246251565e-16\n",
            "Step 510: Cost = 4.440892098500626e-16\n",
            "Step 520: Cost = 5.551115123125783e-16\n",
            "Step 530: Cost = 1.1102230246251565e-16\n",
            "Step 540: Cost = 5.551115123125783e-16\n",
            "Step 550: Cost = 3.3306690738754696e-16\n",
            "Step 560: Cost = 2.220446049250313e-16\n",
            "Step 570: Cost = 7.771561172376096e-16\n",
            "Step 580: Cost = 2.1094237467877974e-15\n",
            "Step 590: Cost = 2.220446049250313e-16\n",
            "Step 600: Cost = 1.1102230246251565e-16\n",
            "Step 610: Cost = 1.1102230246251565e-16\n",
            "Step 620: Cost = 4.440892098500626e-16\n",
            "Step 630: Cost = 3.3306690738754696e-16\n",
            "Step 640: Cost = 2.220446049250313e-16\n",
            "Step 650: Cost = 2.220446049250313e-16\n",
            "Step 660: Cost = 2.220446049250313e-16\n",
            "Step 670: Cost = 1.1102230246251565e-16\n",
            "Step 680: Cost = 0.0\n",
            "Step 690: Cost = 5.551115123125783e-16\n",
            "Step 700: Cost = 5.551115123125783e-16\n",
            "Step 710: Cost = 0.0\n",
            "Step 720: Cost = 2.220446049250313e-16\n",
            "Step 730: Cost = 1.1102230246251565e-16\n",
            "Step 740: Cost = 4.440892098500626e-16\n",
            "Step 750: Cost = 4.440892098500626e-16\n",
            "Step 760: Cost = 3.3306690738754696e-16\n",
            "Step 770: Cost = 9.992007221626409e-16\n",
            "Step 780: Cost = 6.661338147750939e-16\n",
            "Step 790: Cost = 4.440892098500626e-16\n",
            "Step 800: Cost = 2.220446049250313e-16\n",
            "Step 810: Cost = 9.992007221626409e-16\n",
            "Step 820: Cost = 4.440892098500626e-16\n",
            "Step 830: Cost = 1.9984014443252818e-15\n",
            "Step 840: Cost = 2.7755575615628914e-15\n",
            "Step 850: Cost = 7.771561172376096e-16\n",
            "Step 860: Cost = 6.661338147750939e-16\n",
            "Step 870: Cost = 3.6637359812630166e-15\n",
            "Step 880: Cost = 2.55351295663786e-15\n",
            "Step 890: Cost = 2.1094237467877974e-15\n",
            "Step 900: Cost = 0.0\n",
            "Step 910: Cost = 0.0\n",
            "Step 920: Cost = 9.992007221626409e-16\n",
            "Step 930: Cost = 1.2212453270876722e-15\n",
            "Step 940: Cost = 1.1102230246251565e-16\n",
            "Step 950: Cost = 3.219646771412954e-14\n",
            "Step 960: Cost = 9.325873406851315e-15\n",
            "Step 970: Cost = 3.7414515929867775e-14\n",
            "Step 980: Cost = 1.6353585152728556e-13\n",
            "Step 990: Cost = 8.459776212887959e-10\n",
            "Step 1000: Cost = 3.942815006596767e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev = qml.device(\"default.qubit\", wires=m_qubits+c_qubits+a_qubits, shots=10)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def circuit(params, x):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  return qml.sample(wires=m_qubits)\n",
        "\n",
        "samples = circuit(opt_params, xval)\n",
        "#post_measurement_state = qml.state(circuit, conditional=samples)\n"
      ],
      "metadata": {
        "id": "Cr0hP4vpMbgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples"
      ],
      "metadata": {
        "id": "Tq9QOKiEOwP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pennylane.measurements.state import density_matrix\n",
        "def decoding_loop(params, wires):\n",
        "  all_qubits = wires\n",
        "  for j in range(n_layers):\n",
        "    for i, q in enumerate(all_qubits):\n",
        "      k = len(all_qubits) - i - 1\n",
        "      if k+1 < len(all_qubits):\n",
        "        qml.CNOT(wires=[all_qubits[k], all_qubits[k+1]])\n",
        "      for i, q in enumerate(all_qubits):\n",
        "        qml.RY(-params[j, i], wires=q)\n",
        "\n",
        "\n",
        "@qml.qnode(dev)\n",
        "@qml.defer_measurements\n",
        "def circuit_cond(params, x):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  m0 = qml.measure(wires=m_qubits)\n",
        "  print(m0)\n",
        "  qml.cond(m0, decoding_loop)(params, wires=a_qubits+c_qubits)\n",
        "  return qml.density_matrix(wires=a_qubits+c_qubits)\n",
        "\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=m_qubits+c_qubits+a_qubits, shots=10)\n",
        "@qml.qnode(dev)\n",
        "def embedding_circ(x):\n",
        "  phase_embedding_layer(x)\n",
        "  return density_matrix(wires=m_qubits+c_qubits)\n",
        "\n",
        "print(circuit_cond(opt_params, xval))\n",
        "print(embedding_circ(xval))\n",
        "qml.math.fidelity(embedding_circ(xval), circuit_cond(opt_params, xval))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiVBuxkH3vyU",
        "outputId": "ef8400b5-dd29-4b14-e82c-42e2d6a70b16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if 4e968209=0 => 0\n",
            "if 4e968209=1 => 1\n",
            "[[ 0.37249434+0.j          0.04844388+0.06568472j -0.06529836-0.28655129j\n",
            "   0.05502985-0.06069934j]\n",
            " [ 0.04844388-0.06568472j  0.17896133+0.j         -0.13027919-0.05354502j\n",
            "  -0.03549408-0.17610925j]\n",
            " [-0.06529836+0.28655129j -0.13027919+0.05354502j  0.26820203+0.j\n",
            "   0.07853045+0.11758317j]\n",
            " [ 0.05502985+0.06069934j -0.03549408+0.17610925j  0.07853045-0.11758317j\n",
            "   0.18034231+0.j        ]]\n",
            "[[ 0.25      +0.j         -0.03849743+0.24701811j  0.04179864+0.24648098j\n",
            "   0.24606829-0.04416329j]\n",
            " [-0.03849743-0.24701811j  0.25      +0.j          0.23710451-0.07925562j\n",
            "  -0.08152851-0.23633261j]\n",
            " [ 0.04179864-0.24648098j  0.23710451+0.07925562j  0.25      +0.j\n",
            "  -0.00240036-0.24998848j]\n",
            " [ 0.24606829+0.04416329j -0.08152851+0.23633261j -0.00240036+0.24998848j\n",
            "   0.25      +0.j        ]]\n",
            "if e08465f3=0 => 0\n",
            "if e08465f3=1 => 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pennylane/_qubit_device.py:839: UserWarning: Requested state or density matrix with finite shots; the returned state information is analytic and is unaffected by sampling. To silence this warning, set shots=None on the device.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14101694680812446"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLJ-Yn4LCGPH"
      },
      "source": [
        "# MNIST test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNpn33g6CPfU"
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\n",
        "from pennylane import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from PIL import Image\n",
        "\n",
        "# Load MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Reshape images to 8x8 pixels\n",
        "X_train_resized = np.zeros((X_train.shape[0], 8, 8))\n",
        "for i in range(X_train.shape[0]):\n",
        "    img = Image.fromarray(X_train[i])\n",
        "    img = img.resize((8, 8), resample=Image.LANCZOS)\n",
        "    X_train_resized[i] = np.asarray(img)\n",
        "\n",
        "X_test_resized = np.zeros((X_test.shape[0], 8, 8))\n",
        "for i in range(X_test.shape[0]):\n",
        "    img = Image.fromarray(X_test[i])\n",
        "    img = img.resize((8, 8), resample=Image.LANCZOS)\n",
        "    X_test_resized[i] = np.asarray(img)\n",
        "\n",
        "fig, ax = plt.subplots(nrows=2, ncols=5, figsize=(10, 4))\n",
        "for i in range(10):\n",
        "    row = i // 5\n",
        "    col = i % 5\n",
        "    ax[row, col].imshow(X_train_resized[i], cmap='gray')\n",
        "    ax[row, col].set_title(str(y_train[i]))\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xblPfSp-Qcy"
      },
      "outputs": [],
      "source": [
        "n_qubits = 6\n",
        "n_layers = 4\n",
        "measure_qubits = [0,1]\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "def phase_embedding_layer(x):\n",
        "  #qml.AmplitudeEmbedding(features=np.exp(1j * np.pi * x), wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "  qml.AmplitudeEmbedding(features=x, wires=range(n_qubits), pad_with=0.0, normalize=True)\n",
        "\n",
        "def encoding_layer(params):\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(params[i], wires=i)\n",
        "    for i in range(n_qubits):\n",
        "      qml.CNOT(wires=[i, (i+1)%n_qubits])\n",
        "\n",
        "def decoding_layer(params):\n",
        "    for i in range(n_qubits):\n",
        "      k = n_qubits - i - 1\n",
        "      qml.CNOT(wires=[k, (k+1)%n_qubits])\n",
        "    for i in range(n_qubits):\n",
        "        qml.RY(-params[i], wires=i)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def encoding_circuit(params, x, measure_qubits=None):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  if measure_qubits is None:\n",
        "    return qml.state()\n",
        "  if (len(measure_qubits) == 2):\n",
        "    return qml.expval(qml.PauliZ(wires=measure_qubits[0])), qml.expval(qml.PauliZ(wires=measure_qubits[1]))  \n",
        "  return qml.expval(qml.PauliZ(wires=measure_qubits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgqGcpUW_nqg"
      },
      "outputs": [],
      "source": [
        "np.shape(X_train_resized.reshape(60000, 64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_C6W5J5B-4va"
      },
      "outputs": [],
      "source": [
        "opt = qml.AdamOptimizer()\n",
        "\n",
        "def loss_fn(params, X, measure_qubits):\n",
        "  val = encoding_circuit(params, X, measure_qubits=measure_qubits)\n",
        "  return np.mean(np.abs(1-val))\n",
        "\n",
        "\n",
        "params = np.array([\n",
        "    [np.random.uniform(0, 2 * np.pi) for _ in range(n_qubits)] for _ in range(n_layers)\n",
        "], requires_grad=True)\n",
        "tot_iter = 1000\n",
        "batch_size = 500\n",
        "costs=[]\n",
        "xval = X_train_resized.reshape(60000, 64)\n",
        "xval = xval[np.random.choice(xval.shape[0], batch_size, replace=False), :]\n",
        "for i in range(tot_iter):\n",
        "    xval_batch = xval[np.random.choice(xval.shape[0], 100, replace=False), :]\n",
        "    params, cost_val = opt.step_and_cost(lambda v: loss_fn(v, xval_batch, measure_qubits), params)\n",
        "    costs.append(cost_val)\n",
        "    if (i + 1) % (tot_iter/100) == 0:\n",
        "        print('Step {}: Cost = {}'.format(i + 1, cost_val))\n",
        "\n",
        "# Plot cost history\n",
        "plt.plot(costs)\n",
        "plt.xlabel(\"Optimization step\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.ylim(0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mClyfDIdyfY6"
      },
      "source": [
        "# References\n",
        "\n",
        "[1] [Quantum autoencoders with enhanced data encoding](https://arxiv.org/abs/2010.06599)\n",
        "\n",
        "[2] [Quantum neural network autoencoder and classifier applied to an industrial case study\n",
        "](https://link.springer.com/article/10.1007/s42484-022-00070-4)\n",
        "\n",
        "[3] [Quantum computing model of an artificial neuron with continuously valued input data\n",
        "](https://iopscience.iop.org/article/10.1088/2632-2153/abaf98/meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0BadxityaAL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete code for 2-1-2 qubits"
      ],
      "metadata": {
        "id": "lbIbxQfuNDPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 4\n",
        "m_qubits = ['m0']\n",
        "c_qubits = ['c0', 'c1']\n",
        "a_qubits = ['a0']\n",
        "n_qubits = len(m_qubits+c_qubits)\n",
        "dev = qml.device(\"default.qubit\", wires=m_qubits+c_qubits+a_qubits)\n",
        "xval = np.random.uniform(\n",
        "    0,\n",
        "    np.pi,\n",
        "    2**n_qubits\n",
        ") #initial state\n",
        "\n",
        "dev = qml.device(\"default.qubit\", wires=m_qubits+c_qubits+a_qubits)\n",
        "\n",
        "def phase_embedding_layer(x):\n",
        "  qml.AmplitudeEmbedding(features=np.exp(1j * x), wires=m_qubits+c_qubits, pad_with=0.0, normalize=True)\n",
        "\n",
        "def encoding_layer(params):\n",
        "  all_qubits = m_qubits+c_qubits\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    qml.RY(params[i], wires=q)\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    if i + 1 < len(all_qubits):\n",
        "      qml.CNOT(wires=[q, all_qubits[i+1]])\n",
        "\n",
        "def decoding_layer(params):\n",
        "  all_qubits = a_qubits+c_qubits\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    k = len(all_qubits) - i - 1\n",
        "    if k+1 < len(all_qubits):\n",
        "      qml.CNOT(wires=[all_qubits[k], all_qubits[k+1]])\n",
        "  for i, q in enumerate(all_qubits):\n",
        "    qml.RY(-params[i], wires=q)"
      ],
      "metadata": {
        "id": "UvpfmEuhNIZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training\n",
        "opt = qml.AdamOptimizer()\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def encode_loop(params, x):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  return qml.expval(qml.PauliZ(wires=m_qubits))\n",
        "\n",
        "\n",
        "def loss_fn(params, X):\n",
        "  e_val = encode_loop(params, X)\n",
        "  return np.mean(np.abs(1-e_val))\n",
        "\n",
        "params = np.array([\n",
        "    [np.random.uniform(0, 2 * np.pi) for _ in range(n_qubits)] for _ in range(n_layers)\n",
        "], requires_grad=True)\n",
        "opt_params = np.zeros_like(params)\n",
        "tot_iter = 1000\n",
        "costs=[]\n",
        "for i in range(tot_iter):\n",
        "  params, cost_val = opt.step_and_cost(lambda v: loss_fn(v, xval), params)\n",
        "  costs.append(cost_val)\n",
        "  if (i + 1) % (tot_iter/100) == 0:\n",
        "    print('Step {}: Cost = {}'.format(i + 1, cost_val))\n",
        "  opt_params = params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2FxQ-QGNnVZ",
        "outputId": "b985b3e3-6be0-490e-8532-b13259a09c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 10: Cost = 1.4512629500506753\n",
            "Step 20: Cost = 1.2535234274987315\n",
            "Step 30: Cost = 1.026950145148915\n",
            "Step 40: Cost = 0.808267976761307\n",
            "Step 50: Cost = 0.6232082238502752\n",
            "Step 60: Cost = 0.47813304484793906\n",
            "Step 70: Cost = 0.36940387737019065\n",
            "Step 80: Cost = 0.28228203103685345\n",
            "Step 90: Cost = 0.20393866292944807\n",
            "Step 100: Cost = 0.13522429346954\n",
            "Step 110: Cost = 0.0811416003823866\n",
            "Step 120: Cost = 0.04411556726913746\n",
            "Step 130: Cost = 0.022246406583945944\n",
            "Step 140: Cost = 0.010893721949160828\n",
            "Step 150: Cost = 0.005612996134924053\n",
            "Step 160: Cost = 0.0033876035146054306\n",
            "Step 170: Cost = 0.0025256306542371654\n",
            "Step 180: Cost = 0.002196100084764452\n",
            "Step 190: Cost = 0.002042046138650777\n",
            "Step 200: Cost = 0.0019357089586041765\n",
            "Step 210: Cost = 0.0018393274921804093\n",
            "Step 220: Cost = 0.0017446309594536524\n",
            "Step 230: Cost = 0.0016513724374392913\n",
            "Step 240: Cost = 0.0015603421226629832\n",
            "Step 250: Cost = 0.0014719309578054007\n",
            "Step 260: Cost = 0.0013862747315611657\n",
            "Step 270: Cost = 0.0013034531056113074\n",
            "Step 280: Cost = 0.0012235476427294723\n",
            "Step 290: Cost = 0.0011466280261666073\n",
            "Step 300: Cost = 0.0010727340503118299\n",
            "Step 310: Cost = 0.001001872944144666\n",
            "Step 320: Cost = 0.0009340244573619039\n",
            "Step 330: Cost = 0.0008691482128890815\n",
            "Step 340: Cost = 0.0008071905513342692\n",
            "Step 350: Cost = 0.0007480906458975367\n",
            "Step 360: Cost = 0.0006917858359534179\n",
            "Step 370: Cost = 0.0006382157608065819\n",
            "Step 380: Cost = 0.0005873249539330994\n",
            "Step 390: Cost = 0.0005390637324130809\n",
            "Step 400: Cost = 0.0004933874712604869\n",
            "Step 410: Cost = 0.0004502545447936379\n",
            "Step 420: Cost = 0.0004096234185557712\n",
            "Step 430: Cost = 0.00037144950064327276\n",
            "Step 440: Cost = 0.0003356823772050488\n",
            "Step 450: Cost = 0.0003022639587076936\n",
            "Step 460: Cost = 0.0002711278661334804\n",
            "Step 470: Cost = 0.00024220012380760103\n",
            "Step 480: Cost = 0.00021540095474437138\n",
            "Step 490: Cost = 0.00019064725570927532\n",
            "Step 500: Cost = 0.0001678552121847643\n",
            "Step 510: Cost = 0.00014694252269531471\n",
            "Step 520: Cost = 0.00012782982914061325\n",
            "Step 530: Cost = 0.00011044115573055624\n",
            "Step 540: Cost = 9.470338570138903e-05\n",
            "Step 550: Cost = 8.054499408549631e-05\n",
            "Step 560: Cost = 6.789436651255532e-05\n",
            "Step 570: Cost = 5.667805611841992e-05\n",
            "Step 580: Cost = 4.6819278460730196e-05\n",
            "Step 590: Cost = 3.8236850352979523e-05\n",
            "Step 600: Cost = 3.084467777603184e-05\n",
            "Step 610: Cost = 2.4551815466788973e-05\n",
            "Step 620: Cost = 1.9263066117991556e-05\n",
            "Step 630: Cost = 1.488005580585483e-05\n",
            "Step 640: Cost = 1.1302703386006918e-05\n",
            "Step 650: Cost = 8.430985037999328e-06\n",
            "Step 660: Cost = 6.166876616031658e-06\n",
            "Step 670: Cost = 4.41633839132205e-06\n",
            "Step 680: Cost = 3.091195544202563e-06\n",
            "Step 690: Cost = 2.1107697992794883e-06\n",
            "Step 700: Cost = 1.4031369282019313e-06\n",
            "Step 710: Cost = 9.059207548567372e-07\n",
            "Step 720: Cost = 5.665824013290077e-07\n",
            "Step 730: Cost = 3.4221652556176707e-07\n",
            "Step 740: Cost = 1.9891566449548037e-07\n",
            "Step 750: Cost = 1.108021506768253e-07\n",
            "Step 760: Cost = 5.884907150477403e-08\n",
            "Step 770: Cost = 2.9615624175249877e-08\n",
            "Step 780: Cost = 1.4009503224166053e-08\n",
            "Step 790: Cost = 6.163975996287263e-09\n",
            "Step 800: Cost = 2.4859218017425633e-09\n",
            "Step 810: Cost = 8.993786826394512e-10\n",
            "Step 820: Cost = 2.819409150589536e-10\n",
            "Step 830: Cost = 7.185785300123371e-11\n",
            "Step 840: Cost = 1.287481232736809e-11\n",
            "Step 850: Cost = 9.590106486712102e-13\n",
            "Step 860: Cost = 4.4075854077618715e-14\n",
            "Step 870: Cost = 3.489430966396867e-13\n",
            "Step 880: Cost = 3.29847260616134e-13\n",
            "Step 890: Cost = 1.6642243139131097e-13\n",
            "Step 900: Cost = 5.1958437552457326e-14\n",
            "Step 910: Cost = 8.992806499463768e-15\n",
            "Step 920: Cost = 3.3306690738754696e-16\n",
            "Step 930: Cost = 2.220446049250313e-16\n",
            "Step 940: Cost = 9.992007221626409e-16\n",
            "Step 950: Cost = 4.440892098500626e-16\n",
            "Step 960: Cost = 3.3306690738754696e-16\n",
            "Step 970: Cost = 4.440892098500626e-16\n",
            "Step 980: Cost = 1.1102230246251565e-16\n",
            "Step 990: Cost = 2.220446049250313e-16\n",
            "Step 1000: Cost = 2.220446049250313e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot cost history\n",
        "plt.plot(costs)\n",
        "plt.xlabel(\"Optimization step\")\n",
        "plt.ylabel(\"Cost\")\n",
        "plt.ylim(0)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "gspholpgN4w5",
        "outputId": "1063b04a-427c-46e7-bfc2-ec14d5ac3356"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decoding_loop(params, wires):\n",
        "  all_qubits = wires\n",
        "  for j in range(n_layers):\n",
        "    for i, q in enumerate(all_qubits):\n",
        "      k = len(all_qubits) - i - 1\n",
        "      if k+1 < len(all_qubits):\n",
        "        qml.CNOT(wires=[all_qubits[k], all_qubits[k+1]])\n",
        "      for i, q in enumerate(all_qubits):\n",
        "        qml.RY(-params[-(j+1), i], wires=q)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "@qml.defer_measurements\n",
        "def circuit_cond(params, x):\n",
        "  phase_embedding_layer(x)\n",
        "  for i in range(n_layers):\n",
        "    encoding_layer(params[i])\n",
        "  m0 = qml.measure(wires=m_qubits)\n",
        "  qml.cond(m0, decoding_loop)(params, wires=a_qubits+c_qubits)\n",
        "  print(m0)\n",
        "  return qml.density_matrix(wires=a_qubits+c_qubits)\n",
        "\n",
        "@qml.qnode(dev)\n",
        "def embedding_circ(x):\n",
        "  phase_embedding_layer(x)\n",
        "  return qml.density_matrix(wires=m_qubits+c_qubits)\n",
        "\n",
        "print(circuit_cond(opt_params, xval))\n",
        "print(embedding_circ(xval))\n",
        "qml.math.fidelity(embedding_circ(xval), circuit_cond(opt_params, xval))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzWJ9T9JN6I7",
        "outputId": "49d887d6-0f7e-4e8e-869a-0dd5f38d2857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if dcfbeb46=0 => 0\n",
            "if dcfbeb46=1 => 1\n",
            "[[ 5.70138609e-01+6.61666927e-18j -3.95757490e-20+1.90845433e-20j\n",
            "  -1.71991436e-01-7.71133559e-02j -5.18116744e-20-5.50072092e-20j\n",
            "   4.65194313e-02+4.28271057e-01j  5.71561866e-20+6.77990851e-20j\n",
            "   5.13505775e-02-1.46068525e-01j -4.75819030e-20-2.47558792e-20j]\n",
            " [-3.95757490e-20-1.90845433e-20j  6.63651247e-20-4.22987569e-37j\n",
            "  -4.53076827e-20+3.37630405e-20j  3.44018945e-20+1.08831920e-19j\n",
            "   1.82185976e-20+7.82314883e-20j -3.32806929e-20-1.29742120e-19j\n",
            "   1.32824094e-20+5.67536145e-22j  4.84946432e-20+6.48989644e-20j]\n",
            " [-1.71991436e-01+7.71133559e-02j -4.53076827e-20-3.37630405e-20j\n",
            "   6.23138356e-02+4.03733602e-19j  3.18816005e-20-9.18017509e-20j\n",
            "  -7.19585756e-02-1.22902893e-01j -4.32850442e-20+1.05506803e-19j\n",
            "   4.26558484e-03+5.10092637e-02j -9.03116620e-23-6.89782218e-20j]\n",
            " [-5.18116744e-20+5.50072092e-20j  3.44018945e-20-1.08831920e-19j\n",
            "   3.18816005e-20+9.18017509e-20j  1.96306074e-19-5.01669391e-36j\n",
            "   1.37735556e-19+1.06764880e-20j -2.30015432e-19-1.26779391e-20j\n",
            "   7.81594394e-21-2.14875780e-20j  1.31565887e-19-4.58843075e-20j]\n",
            " [ 4.65194313e-02-4.28271057e-01j  1.82185976e-20-7.82314883e-20j\n",
            "  -7.19585756e-02+1.22902893e-01j  1.37735556e-19-1.06764880e-20j\n",
            "   3.25500068e-01+8.64427660e-18j -1.62076794e-19+3.61452904e-21j\n",
            "  -1.05532446e-01-5.04912146e-02j  8.98159538e-20-3.93495832e-20j]\n",
            " [ 5.71561866e-20-6.77990851e-20j -3.32806929e-20+1.29742120e-19j\n",
            "  -4.32850442e-20-1.05506803e-19j -2.30015432e-19+1.26779391e-20j\n",
            "  -1.62076794e-19-3.61452904e-21j  2.70332079e-19+8.16260648e-37j\n",
            "  -7.77036331e-21+2.56821630e-20j -1.51194842e-19+6.22603410e-20j]\n",
            " [ 5.13505775e-02+1.46068525e-01j  1.32824094e-20-5.67536145e-22j\n",
            "   4.26558484e-03-5.10092637e-02j  7.81594394e-21+2.14875780e-20j\n",
            "  -1.05532446e-01+5.04912146e-02j -7.77036331e-21-2.56821630e-20j\n",
            "   4.20474871e-02+0.00000000e+00j  1.02607840e-20+1.25742573e-20j]\n",
            " [-4.75819030e-20+2.47558792e-20j  4.84946432e-20-6.48989644e-20j\n",
            "  -9.03116620e-23+6.89782218e-20j  1.31565887e-19+4.58843075e-20j\n",
            "   8.98159538e-20+3.93495832e-20j -1.51194842e-19-6.22603410e-20j\n",
            "   1.02607840e-20-1.25742573e-20j  9.89014341e-20+0.00000000e+00j]]\n",
            "[[ 0.125     +3.16508307e-18j -0.0805286 -9.56041026e-02j\n",
            "   0.12115798+3.07529351e-02j  0.12452522-1.08843644e-02j\n",
            "   0.0931028 -8.34078483e-02j  0.05566593-1.11920975e-01j\n",
            "  -0.00575996-1.24867221e-01j  0.1246408 +9.46946100e-03j]\n",
            " [-0.0805286 +9.56041026e-02j  0.125     +3.02849675e-18j\n",
            "  -0.10157432+7.28536757e-02j -0.07189802+1.02252997e-01j\n",
            "   0.00381356+1.24941814e-01j  0.04973924+1.14677843e-01j\n",
            "   0.09921328+7.60376538e-02j -0.08753975+8.92288760e-02j]\n",
            " [ 0.12115798-3.07529351e-02j -0.10157432-7.28536757e-02j\n",
            "   0.125     -5.48651321e-20j  0.11801999-4.11859494e-02j\n",
            "   0.06972089-1.03749688e-01j  0.02641978-1.22176082e-01j\n",
            "  -0.03630319-1.19612200e-01j  0.12313953-2.14861573e-02j]\n",
            " [ 0.12452522+1.08843644e-02j -0.07189802-1.02252997e-01j\n",
            "   0.11801999+4.11859494e-02j  0.125     +1.72177807e-18j\n",
            "   0.1000119 -7.49841276e-02j  0.0652    -1.06648768e-01j\n",
            "   0.00513472-1.24894494e-01j  0.12334283+2.02865810e-02j]\n",
            " [ 0.0931028 +8.34078483e-02j  0.00381356-1.24941814e-01j\n",
            "   0.06972089+1.03749688e-01j  0.1000119 +7.49841276e-02j\n",
            "   0.125     -2.78325572e-18j  0.11614193-4.62174465e-02j\n",
            "   0.0790291 -9.68473078e-02j  0.08651664+9.02212347e-02j]\n",
            " [ 0.05566593+1.11920975e-01j  0.04973924-1.14677843e-01j\n",
            "   0.02641978+1.22176082e-01j  0.0652    +1.06648768e-01j\n",
            "   0.11614193+4.62174465e-02j  0.125     -1.43024437e-18j\n",
            "   0.10923702-6.07640787e-02j  0.04702731+1.15816371e-01j]\n",
            " [-0.00575996+1.24867221e-01j  0.09921328-7.60376538e-02j\n",
            "  -0.03630319+1.19612200e-01j  0.00513472+1.24894494e-01j\n",
            "   0.0790291 +9.68473078e-02j  0.10923702+6.07640787e-02j\n",
            "   0.125     +0.00000000e+00j -0.01520281+1.24072054e-01j]\n",
            " [ 0.1246408 -9.46946100e-03j -0.08753975-8.92288760e-02j\n",
            "   0.12313953+2.14861573e-02j  0.12334283-2.02865810e-02j\n",
            "   0.08651664-9.02212347e-02j  0.04702731-1.15816371e-01j\n",
            "  -0.01520281-1.24072054e-01j  0.125     +0.00000000e+00j]]\n",
            "if b903fc25=0 => 0\n",
            "if b903fc25=1 => 1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.047742917799923026"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}